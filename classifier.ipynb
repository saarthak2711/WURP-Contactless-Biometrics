{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "num_classes = 336\n",
    "vit_model = ViTClassifier(num_classes)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vit_model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "print(\"Training started...\")\n",
    "for epoch in range(10):  \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "  \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{10}', leave=False)\n",
    "    \n",
    "    \n",
    "    for inputs, labels in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        outputs = vit_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "       \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "      \n",
    "        progress_bar.set_postfix({'loss': running_loss / total, 'accuracy': 100 * correct / total})\n",
    "\n",
    "print('Training finished.')\n",
    "\n",
    "\n",
    "vit_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = vit_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print('Test Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Embeddings Shape: (196, 768)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pre-trained ViT model\n",
    "vit_model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "vit_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Access positional embeddings\n",
    "positional_embeddings = vit_model.pos_embed\n",
    "\n",
    "# Remove the class token embedding (first token) if it exists\n",
    "if positional_embeddings.shape[1] > 1:\n",
    "    positional_embeddings = positional_embeddings[:, 1:, :]\n",
    "\n",
    "# Convert to numpy array for inspection\n",
    "positional_embeddings_np = positional_embeddings.detach().cpu().numpy().reshape(-1, positional_embeddings.size(-1))\n",
    "\n",
    "print(\"Positional Embeddings Shape:\", positional_embeddings_np.shape)\n",
    "\n",
    "# Visualize positional embeddings\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(positional_embeddings_np.T, cmap='viridis', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Patch Index')\n",
    "plt.ylabel('Embedding Dimension')\n",
    "plt.title('Positional Embeddings Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
    "        \n",
    "        self.activation = {}\n",
    "        \n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                self.activation[name] = output.detach()\n",
    "            return hook\n",
    "        \n",
    "        \n",
    "        self.model.blocks[-1].attn.register_forward_hook(get_activation('last_attention'))\n",
    "        self.model.blocks[-1].mlp.register_forward_hook(get_activation('last_mlp'))\n",
    "        self.model.blocks[-1].norm1.register_forward_hook(get_activation('last_norm1'))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "num_classes = 336\n",
    "vit_model = ViTClassifier(num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vit_model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "print(\"Training started...\")\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{10}', leave=False)\n",
    "    \n",
    "    for inputs, labels in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = vit_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': running_loss / total, 'accuracy': 100 * correct / total})\n",
    "\n",
    "print('Training finished.')\n",
    "\n",
    "\n",
    "vit_model.eval()\n",
    "top_images = []\n",
    "top_activations = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = vit_model(inputs)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        top_probs, top_indices = torch.topk(probabilities, k=30, dim=1)\n",
    "        \n",
    "        for i in range(inputs.size(0)):\n",
    "            if labels[i] in top_indices[i]:\n",
    "                top_images.append(inputs[i])\n",
    "                top_activations.append({\n",
    "                    'last_attention': vit_model.activation['last_attention'][i],\n",
    "                    'last_mlp': vit_model.activation['last_mlp'][i],\n",
    "                    'last_norm1': vit_model.activation['last_norm1'][i],\n",
    "                    \n",
    "                })\n",
    "                if len(top_images) == 30:\n",
    "                    break\n",
    "        if len(top_images) == 30:\n",
    "            break\n",
    "\n",
    "\n",
    "for i in range(len(top_images)):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(transforms.functional.to_pil_image(top_images[i]))\n",
    "    plt.title(f'Top Image {i + 1}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(top_activations[i]['last_attention'][0].cpu().numpy(), cmap='hot', interpolation='nearest')\n",
    "    plt.title(f'Last Attention Map')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(top_activations[i]['last_mlp'][0].cpu().numpy(), cmap='hot', interpolation='nearest')\n",
    "    plt.title(f'Last MLP Activation')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(top_activations[i]['last_norm1'][0].cpu().numpy(), cmap='hot', interpolation='nearest')\n",
    "    plt.title(f'Last Norm1 Activation')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = vit_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print('Test Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
